{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Классификация текстов: спам-фильтр для SMS\n",
    "В этом задании вам предстоит взять открытый датасет с SMS-сообщениями, размеченными на спам (\"spam\") и не спам (\"ham\"), построить на нем классификатор текстов на эти два класса, оценить его качество с помощью кросс-валидации, протестировать его работу на отдельных примерах, и посмотреть, что будет происходить с качеством, если менять параметры вашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1)** Загрузите датасет. Подготовьте для дальнейшей работы два списка: список текстов в порядке их следования в датасете и список соответствующих им меток классов. В качестве метки класса используйте 1 для спама и 0 для \"не спама\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vlad\\Machine_Learning\\Yandex Specialization\\5.Applied Tasks Of Data Analysis\\data\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\vlad\\Machine_Learning\\Yandex Specialization\\5.Applied Tasks Of Data Analysis\\data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>is_spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                               text  is_spam\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        0\n",
       "1   ham                      Ok lar... Joking wif u oni...        0\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        1\n",
       "3   ham  U dun say so early hor... U c already then say...        0\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('SMSSpamCollection.txt', sep='\\t', header=None, names=['class', 'text'])\n",
    "data['is_spam'] = data['class'].map({'ham':0,'spam':1})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts Size:  5572\n"
     ]
    }
   ],
   "source": [
    "print('Texts Size: ', data['text'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2)** Используя ```sklearn.feature_extraction.text.CountVectorizer``` со стандартными настройками, получите из списка текстов матрицу признаков ```x```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  8713\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,1))\n",
    "feature_matrix = vectorizer.fit_transform(data['text'])\n",
    "print('Number of Features: ', feature_matrix.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3)** Оцените качество классификации текстов с помощью ```LogisticRegression()``` с параметрами по умолчанию, используя ```sklearn.cross_validation.cross_val_score``` и посчитав среднее арифметическое качества на отдельных фолдах.\n",
    "\n",
    "Установите ```random_state=2```. Параметр ```cv``` задайте равным 10. В качестве метрики качества используйте ```f1-меру```. Получившееся качество - один из ответов, которые потребуются при сдаче задания. Ответ округлить до 1 знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1 Score Using 10 Folds: 0.9312\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "log_reg_model = LogisticRegression(random_state=2)\n",
    "\n",
    "cv_score = cross_val_score(log_reg_model, feature_matrix, data['is_spam'], scoring='f1', cv=10, n_jobs=-1).mean()\n",
    "print('Avg F1 Score Using 10 Folds: %.4f' %cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vlad\\Machine_Learning\\Yandex Specialization\\5.Applied Tasks Of Data Analysis\\submissions\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\vlad\\Machine_Learning\\Yandex Specialization\\5.Applied Tasks Of Data Analysis\\submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определим функции для сохранения скаляров и списков значений\n",
    "def save_value(f_name, value):\n",
    "    with open(f_name, 'w') as f:\n",
    "        f.write(str(value))\n",
    "        \n",
    "def save_value_list(f_name, values):\n",
    "    with open(f_name, 'w') as f:\n",
    "        f.write(' '.join([str(value) for value in values]))\n",
    "    \n",
    "    \n",
    "save_value('spam_classification_1.txt', round(cv_score,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4**) А теперь обучите классификатор на всей выборке и спрогнозируйте с его помощью класс для следующих сообщений:\n",
    "- \"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\"\n",
    "- \"FreeMsg: Txt: claim your reward of 3 hours talk time\"\n",
    "- \"Have you visited the last lecture on physics?\"\n",
    "- \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\"\n",
    "\n",
    "- \"Only 99$\"\n",
    "\n",
    "Прогнозы классификатора (0 - не спам, 1 - спам), записанные через пробел, будут ответом в одном из вопросов ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\n",
      "SPAM\n",
      "\n",
      "FreeMsg: Txt: claim your reward of 3 hours talk time\n",
      "SPAM\n",
      "\n",
      "Have you visited the last lecture on physics?\n",
      "HAM\n",
      "\n",
      "Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\n",
      "HAM\n",
      "\n",
      "Only 99$\n",
      "HAM\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Обучаем\n",
    "log_reg_model.fit(feature_matrix, data['is_spam'])\n",
    "\n",
    "# Протестируем классификатор на примерах\n",
    "texts = [\n",
    "    \"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "    \"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "    \"Have you visited the last lecture on physics?\",\n",
    "    \"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "    \"Only 99$\"\n",
    "]\n",
    "\n",
    "\n",
    "results = []\n",
    "for text in texts:\n",
    "    print(text)\n",
    "    pred = log_reg_model.predict(vectorizer.transform([text]))[0]\n",
    "    results.append(pred)\n",
    "    if pred == 1:\n",
    "        print('SPAM')\n",
    "    else:\n",
    "        print('HAM')\n",
    "    print()\n",
    "    \n",
    "# Сохраняем результаты\n",
    "save_value_list('spam_classification_2.txt', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5)** Задайте в ```CountVectorizer``` параметр ```ngram_range=(2,2)```, затем ```ngram_range=(3,3)```, затем ```ngram_range=(1,3)```. Во всех трех случаях измерьте получившееся в кросс-валидации значение f1-меры, округлите до второго знака после точки, и выпишете результаты через пробел в том же порядке.\n",
    "\n",
    "В данном эксперименте мы пробовали добавлять в признаки n-граммы для разных диапазонов n - только биграммы, только триграммы, и, наконец, все вместе - униграммы, биграммы и триграммы. **Обратите внимание**, что статистики по биграммам и триграммам намного меньше, поэтому классификатор только на них работает хуже. В то же время это не ухудшает результат сколько-нибудь существенно, если добавлять их вместе с униграммами, т.к. за счет регуляризации линейный классификатор не склонен сильно переобучаться на этих признаках."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  41793\n",
      "Avg F1 Score Using 10 Folds: 0.8169\n",
      "\n",
      "Number of Features:  54461\n",
      "Avg F1 Score Using 10 Folds: 0.7250\n",
      "\n",
      "Number of Features:  104967\n",
      "Avg F1 Score Using 10 Folds: 0.9217\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "n_grams_params = [(2,2), (3,3), (1,3)] \n",
    "log_reg_model = LogisticRegression(random_state=2)\n",
    "results = []\n",
    "\n",
    "for n_grams_param in n_grams_params:\n",
    "    vectorizer = CountVectorizer(ngram_range=n_grams_param)\n",
    "    feature_matrix = vectorizer.fit_transform(data['text'])\n",
    "    print('Number of Features: ', feature_matrix.shape[1])\n",
    "    cv_score = cross_val_score(log_reg_model, feature_matrix, data['is_spam'], scoring='f1', cv=10, n_jobs=-1).mean()\n",
    "    print('Avg F1 Score Using 10 Folds: %.4f' %cv_score)\n",
    "    results.append(round(cv_score, 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Действительно, качество для триграмм заметно хуже (хоть признаков и много, но полезной статистики мало). Идельным оказался вариант комбинирования униграмм и биграмм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_value_list('spam_classification_3.txt', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6)** Аналогично предыдущему эксперименту используйте вместо логистической регрессии ```MultinomialNB()```.\n",
    "\n",
    "Обратите внимание, насколько сильнее (по сравнению с линейным классификатором) наивный Байес страдает от нехватки статистики по биграммам и триграммам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features:  41793\n",
      "Avg F1 Score Using 10 Folds: 0.6458\n",
      "\n",
      "Number of Features:  54461\n",
      "Avg F1 Score Using 10 Folds: 0.3786\n",
      "\n",
      "Number of Features:  104967\n",
      "Avg F1 Score Using 10 Folds: 0.8885\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "mul_nb_classifier = MultinomialNB()\n",
    "n_grams_params = [(2,2), (3,3), (1,3)]\n",
    "results = []\n",
    "\n",
    "for n_grams_param in n_grams_params:\n",
    "    vectorizer = CountVectorizer(ngram_range=n_grams_param)\n",
    "    feature_matrix = vectorizer.fit_transform(data['text'])\n",
    "    print('Number of Features: ', feature_matrix.shape[1])\n",
    "    cv_score = cross_val_score(mul_nb_classifier, feature_matrix, data['is_spam'], scoring='f1', cv=10, n_jobs=-1).mean()\n",
    "    print('Avg F1 Score Using 10 Folds: %.4f' %cv_score)\n",
    "    results.append(round(cv_score, 2))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_value_list('spam_classification_4.txt', results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметно, что качество наивного байеса заметно ниже для биграмм и триграмм. Классификатор явно хуже справляется с задачей, чем логистическая регрессия.\n",
    "\n",
    "**7)** Попробуйте использовать в логистической регрессии в качестве признаков ```Tfidf``` из ```TfidfVectorizer``` на униграммах. Повысилось или понизилось качество на кросс-валидации по сравнению с ```CountVectorizer``` на униграммах? (напишите в файле с ответом 1, если повысилось, -1, если понизилось, и 0, если изменилось не более чем на 0.01). \n",
    "\n",
    "Обратите внимание, что результат перехода к ```tfidf``` не всегда будет таким - если вы наблюдаете какое-то явление на одном датасете, не надо сразу же его обобщать на любые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg F1 Score Using 10 Folds: 0.8520\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2)\n",
    "\n",
    "log_reg_model = LogisticRegression(random_state=2)\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 1))\n",
    "\n",
    "feature_matrix = tfidf_vectorizer.fit_transform(data['text'])\n",
    "\n",
    "cv_score = cross_val_score(log_reg_model, feature_matrix, data['is_spam'], scoring='f1', cv=10, n_jobs=-1).mean()\n",
    "print('Avg F1 Score Using 10 Folds: %.4f' %cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основное различие между TfidfVectorizer и TfidfTransformer:\n",
    "- TfidfVectorizer комбинирует в себе CountVectorizer и TfidfTransformer (т.е. сначала получает частоты слов, затем значения tf-idf)\n",
    "- TfidfTransformer применяется к матрице частот слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_value('spam_classification_5.txt', -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

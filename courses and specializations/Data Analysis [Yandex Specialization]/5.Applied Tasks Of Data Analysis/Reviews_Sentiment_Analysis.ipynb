{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ тональности отзывов\n",
    "В качестве выборки возьмем отзывы на фильмы из библиотеки NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pos/cv000_29590.txt',\n",
       " 'pos/cv001_18431.txt',\n",
       " 'pos/cv002_15918.txt',\n",
       " 'pos/cv003_11664.txt',\n",
       " 'pos/cv004_11636.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import movie_reviews\n",
    "\n",
    "# Возьмем ids негативных и позитивных отзывов\n",
    "neg_ids = movie_reviews.fileids('neg')\n",
    "pos_ids = movie_reviews.fileids('pos')\n",
    "\n",
    "pos_ids[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подготовим обучающую выборку (тексты и классы)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Labels:  2000\n"
     ]
    }
   ],
   "source": [
    "# Загружаем негативные и позитивные отзывы, и собираем наш текст отзывов\n",
    "neg_reviews = [' '.join(movie_reviews.words(fileids=[file])) for file in neg_ids]\n",
    "pos_reviews = [' '.join(movie_reviews.words(fileids=[file])) for file in pos_ids]\n",
    "\n",
    "reviews = neg_reviews + pos_reviews\n",
    "\n",
    "# Создаем метки классов\n",
    "labels = [0] * len(neg_reviews) + [1] * len(pos_reviews)\n",
    "print('Total Labels: ', len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the happy bastard \\' s quick movie review damn that y2k bug . it \\' s got a head start in this movie starring jamie lee curtis and another baldwin brother ( william this time ) in a story regarding a crew of a tugboat that comes across a deserted russian tech ship that has a strangeness to it when they kick the power back on . little do they know the power within . . . going for the gore and bringing on a few action sequences here and there , virus still feels very empty , like a movie going for all flash and no substance . we don \\' t know why the crew was really out in the middle of nowhere , we don \\' t know the origin of what took over the ship ( just that a big pink flashy thing hit the mir ) , and , of course , we don \\' t know why donald sutherland is stumbling around drunkenly throughout . here , it \\' s just \" hey , let \\' s chase these people around with some robots \" . the acting is below average , even from the likes of curtis . you \\' re more likely to get a kick out of her work in halloween h20 . sutherland is wasted and baldwin , well , he \\' s acting like a baldwin , of course . the real star here are stan winston \\' s robot design , some schnazzy cgi , and the occasional good gore shot , like picking into someone \\' s brain . so , if robots and body parts really turn you on , here \\' s your movie . otherwise , it \\' s pretty much a sunken ship of a movie .'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Взглянем на один отзыв\n",
    "reviews[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция ниже создана для удобства оценивания различных моделей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline создаст частоты слов, затем на основе частот вычислит TFIDF, полученная матрица признаков затем классифицируется\n",
    "def model_pipeline(vectorizer, transformer, classifier):\n",
    "    return Pipeline([\n",
    "      ('vectorizer', vectorizer),\n",
    "      ('transformer', transformer),\n",
    "      ('classifier', classifier)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним качество различных классификаторов на данных отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.linear_model._logistic.LogisticRegression'>\n",
      "0.8205\n",
      "\n",
      "<class 'sklearn.svm._classes.LinearSVC'>\n",
      "0.8545\n",
      "\n",
      "<class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
      "0.857\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for classifier in [LogisticRegression, LinearSVC, SGDClassifier]:\n",
    "    print(classifier)\n",
    "    print(cross_val_score(model_pipeline(CountVectorizer(), TfidfTransformer(), classifier()), reviews, labels).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем случае оказались хороши 2 модели, возьмем как итоговую SGDClassifier. Обучим его на всех отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('vectorizer', TfidfVectorizer()),\n",
       "                ('classifier', SGDClassifier())])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Здесь используем сразу TfidfVectorizer(), он комбинирует в себе CountVectorizer() и TfidfTransformer()\n",
    "\n",
    "classifier = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', SGDClassifier())\n",
    "    \n",
    "])\n",
    "\n",
    "classifier.fit(reviews, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пример классификации отзыва\n",
    "Помним, что 0 - негативный, 1 - положительный. Однако даже учитывая относительно неплохое качество, классификатор можно легко обмануть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(['Yesterday I decided to watch a film called the mummy. The film surprised me!']))\n",
    "print(classifier.predict(['Yesterday I decided to watch a film called the mummy. The film is not as bad as I expected. I had a great time']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем как-нибудь улучшить качество модели\n",
    "\n",
    "### Понижение размерности и ансамбли деревьев\n",
    "Поробуем применить различные матричные разложения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF, TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 39659)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Найдем для начала матрицу частот слов и взглянем на её размерность\n",
    "c_vec = CountVectorizer()\n",
    "feature_matrix = c_vec.fit_transform(reviews)\n",
    "feature_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Число признаков в 39к действительно много. Попробуем понизить размерность и применить модели посложней, например, деревья."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Неотрицательное матричное разложение NMF\n",
    "nmf = NMF(10)\n",
    "\n",
    "# Понизим размерность до 10 признаков\n",
    "nmf_feature_matrix = nmf.fit_transform(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD\n",
    "svd = TruncatedSVD(10)\n",
    "\n",
    "# Понизим размерность до 10 признаков\n",
    "svd_feature_matrix = svd.fit_transform(feature_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним теперь SVD и NMF используя pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.decomposition._truncated_svd.TruncatedSVD'>\n",
      "0.5385000000000001\n",
      "<class 'sklearn.decomposition._nmf.NMF'>\n",
      "0.655\n"
     ]
    }
   ],
   "source": [
    "for dec_method in [TruncatedSVD, NMF]:\n",
    "    print(dec_method)\n",
    "    print(cross_val_score(model_pipeline(CountVectorizer(), dec_method(n_components=10), LinearSVC()), reviews, labels).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество явно стало ниже, возможно число компонент равно 10 недостаточно. Посмотрим на результаты с 1000 компонентами. Возьмем TruncatedSVD, т.к. NMF c 1000 компонентами преобразует очень долго. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.849\n",
      "Wall time: 1min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "print(cross_val_score(model_pipeline(TfidfVectorizer(),\n",
    "                               TruncatedSVD(n_components=1000),\n",
    "                               LinearSVC()), reviews, labels).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим вы молучили исходное качество, но уже с меньшим числом признаков. Возможно, используя деревья мы сможем улучшить качество?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ансамбли деревьев на признаках меньшей размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7335\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "print(cross_val_score(Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('transformer', TruncatedSVD(n_components=100)),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100))\n",
    "]), reviews, labels).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Особо не помагло, увеличим до 1000 число деревьев и компонент"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7244999999999999\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('transformer', TruncatedSVD(n_components=1000)),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=1000))\n",
    "]), reviews, labels).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тоже не помагло, качество даже еще чуть просело. Может нужно вместо частот слов использовать TFIDF?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.631\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('transformer', TruncatedSVD(n_components=1000)),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=1000))\n",
    "]), reviews, labels).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество еще сильней упало. Может необходмо совместить признаки из TFIDF и из SVD разложения? Возможно неплохая идея."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion # объединяет преобразования и получает единое множество признаков\n",
    "\n",
    "# Добавим одну компоненту из SVD разложения \n",
    "estimators = [('tfidf', TfidfTransformer()), ('svd', TruncatedSVD(1))]\n",
    "combined = FeatureUnion(estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6775\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('transformer', combined),\n",
    "    ('classifier', LinearSVC())\n",
    "]), reviews, labels).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество получилось ниже. Таким образом отправной бейзлайн был очень хороший."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

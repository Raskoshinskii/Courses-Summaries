Week_1
- Что такое машинное обучение?
- Основные виды обучение в МО
- Интерполяция
- Основная задача обучения с учителем
- Объект, ответ, признак, признаковое описание
- Определение алгоритма МО
- Функционал ошибки
- Постановка задачи обучения в МО (обучение с учителем)
- Нотация Айверсона
- Ключевые вопросы в МО
- Основные типы задач МО (обучение с учителем)
- Основные типы задач МО (обучение без учителем)
- Основные типы признаков в МО
- Выбросы, в чем проблема?
- Проблема редких значений категориальных признаков
- Проблема скошенности вещественных признаков
- Какие вопросы мы должны обязательно задать при решении задачи МО? (например регрессии)
- Формула модели линейной регрессии
- Какую функцию ошибки минимизируем и почему?
- Задача обучения линейной регрессии в матричном виде
- Аналитическая формула нахождения весов ЛР
- Недостаток аналитического подхода
- Алгоритм градиентного спуска в ЛР (инициализация весов, формула)
- Какие критерии останова градиентного спуска могут быть определены?
- Что такое парная регрессия?
- Как можно выбрать шаг градиентного спуска?
- Стохастический градиентный спуск (формула)
- Отличия между SGD и GD
- Достоинства SGD
- Что такое онлайн обучение?
- Что такое линейный классификатор (формула)
- Геометрический смысл ЛК (гиперплоскость, расстояние от объекта до гиперплоскости)
- Отступ...О чем говорит знак отступа и модуль отступа
- Функция потерь для задачи бинарной классфификации (основные проблемы, пути решения
Week_2
- Переобучение, недообучение и способы выявления переобучения
- Регуляризация и проблема мультиколлинеарности
- L2 и L1 регуляризация. Основные отличия. Гиперпараметр ламбда
- Чему эквивалентна регуляризация?
- Методы оценки качества алгоритмов (отложенная выборка, много ОВ, кросс-валидация, достоинства и недостатки)
- Что такое гиперпараметры модели?
- Как следует осуществлять выбор лучших алгоритмов и гиперпараметров
- Можно ли обучаться на 1 метрике, а проверять на другой?
- Основные метрики качества в задачах регрессии (достоинства/недостатки)
- Может ли R^2 быть отрицательным, что это означает?
- Пример нессиметричной метрики качества в задаче регрессии
- Вероятностный смысл метрик в задачах регрессии
- Основное отличие метрик в задачах регрессии и классификации?
- Чем плоха "обычная точность" в классификаци?
- Основные метрики классификации, матрица ошибок, интерператция Accuracy, Precision, Recall
- Что такое ошибки первого и второго рода?
- Интерпертация F-меры..Зачем она нужна?
- Формула F-меры и расширенной F-меры. Интерпретация коэффициета бетта
- Зачем нужно оценивать принадлежность к классу?
- Оценка принадлежности к классу при помощи PRC-Curve
- Координаты точки PRC-Curve для идеального классификатора
- Оценка принадлежности к классу при помощи ROC-Curve
- Определения TPR, FPR, чувствительности и спецефичности
- Алгоритм построения ROC-кривой
- Координаты точки ROC-Curve для идеального классификатора
- Что такое ROC-AUC, в каких пределах изменяется
- Можно ли одновременно повышать чувствительность и спецефичность классификатора?
- PRC-AUC и ROC-AUC зачем нужны и их чувствительность к балансу классов?
- Что характеризует линия на графике ROC-Curve, проходящая от нуля до 1
Week_3
- Что такое метод максимального правдоподобия (опиши постановку задачи)?
- Что такое функция правдоподобия?
- Полезные свойства ММП
- Что такое функции семейства дивергенции Брегмана. Какая оценка обеспечивает минимум для таких ФП?
- Что является лучшей линейной аппроксимацией для среднеабсолютной ошибки и квантильной ошибки?
- Как еще можно бороться с переобучением?
- Формулы для Ridge и Lasso Regression
- Следует ли использовать еденичный признак (вес w0) в регуляризаторе?
- Как изменяются значения весов для МНК, Ridge и Lasso регрессии?
- График зависимости весов от Y для МНК, Ridge и Lasso регрессии (основное отличие)
- Из чего складывается математическое ожидание квадрата ошибки регрессии? (декомпозиция ошибки)
- Графики баланса между смещением и дисперсией (Bias-Variance Trade off)
- Каковы значения смещения и дисперсии для модели переобученной и с регуляризацией?
- Аналитическое решение для Ridge и Lasso Regression
  - Метод LDA. Что это такое?
  - Основная цель метода LDA?
  - Основные задачи метода LDA?
  - Что такое дискриминантные признаки, дискриминируящая функция?
  - Как проводится гиперплоскость между классами в LDA?
  - Основные +/- LDA
  - Является ли LDA полноценным классификаторм?
- Как работает Линейный Дискриминант Фишера?
- Что такое логистическая регрессия? (бинарная классфификация)
- Что предсказываем в логистической регрессии?
- Переход от вещественных предсказаний линейной модели к вероятности
- Что такое логит преобразование?
- Как обучается логистическая регрессия?
- Как меняется функция потерь в зависимости от меток класса?
- Почему лучше использовать LogLoss, а не МНК в качестве функции потерь?
- К максимизации чего приводит минимизация логистической функции потерь?
- LogLoss и кросс-энтропия это одно и тоже?
- Что будет если метки класса идеально разделимы линейно?
- Регуляризация для логистической регрессии
- Как связана однослойная нейронная сеть и логистическая регрессия?
- Необходимость масштабирования признаков
- Нормализация средним и мин/макс нормализация
- Понятие спремляющего пространства (примеры)
- Какие признаки можно добавить в линейную модель чтобы повысить пространство?
- К какой проблеме может привести создание новых признаков?
- К чему приводит логарифмирование распределения таргета?
- В чем основное отличие категориальных признаков от порядковых?
- Как кодируют категориальные признаки для моделей?
- Когда выборку можно считать несбалансированной?
- Какой класс будет предсказывать классификатор, если классы несбалансированны?
- Основные методы борьбы с дисбалансом классов (что является гиперпараметром в этих методах)?
- Каким методом можно решить задачу многоклассовой классификации?
- Какие метрики используются для задач многоклассовой классификации и как их рассчитать?
- Как предсказывается класс в задаче мультиклассовой классификации
Week_4
- Дерево решений (краткое определение, как влияет тип задачи на значения в листьях)
- К какому классу моделей относится ДР?
- Как строят ДР в МО и почему?
- Как может быть определен ответ в листе ДР?
- Что мы пытаемся минимизировать при разбиении вершины?
- Формула критерия ошибки для разбиения вершины (что представляет из себя каждый параметр такой ошибки)
- Критерии информативности для регрессии и классификации (критерий Джини и Энтропийный критерий)
- Когда достигается оптимум критерия Джини и Энтропии?
- Интерпертация энтропийного критерия и критерия Джини
- В чем отличие критерия Джини (Gini Impurity) от индекса Джини (Gini Index)
- Прирост информации, зачем нужен?
- Основные критерии останова и стрижка ДР
- Основной минус стрижки деревьев?
- Основыне отличия между ID3, C4.5 и CART алгоритмов ДР
- Что такое композиция алгоритмов?
- Суть Бутсрэпа и зачем он используется в композиции деревьев?
- На какие параметры обычно раскладывается ошибка моделей?
- Что такое шум, смещение и разброс
- Каким смещением и разбросом обладают: линейные модели, решающие деревья и композиции алгоритмов?
- Каким основным свойством должны обладать алгоритмы композиций (ensembles)
- Основные методы снижения зависимости между базовыми алгоритмами?
- Как влияет размер выборки на переобучение и зависимость между алгоритмами в Бэгинге (Бутсрэп)?
- Какой гиперпараметр появляется в методе случайных подпространств?
- Какой недостаток появляется при комбинации методов случайных подпространств и бэггинга?
- Каким способом снижают корреляцию между деревьями в алгоритме случайного леса?
- Rule of Thumb для определения числа признаков в подмножестве признаков (регрессия и классификация)
- Алгоритм построения случайного леса
- Склонен ли случайный лес к переобучению при росте числа деревьев?
- В чем суть подхода "Out of Bag"
- Можно ли оценивать важность признаков при помощи подхода "Out-of-Bag"
- Почему случайный лес применим не ко всем задачам. Что делать в этом случае?
- Что такое бустинг?
- Описать как происходит уменьшение ошибки в бустинге (напримере MSE, формула в общем виде)
- Алгоритм градиентного бустинга
  - Какими способоми может быть проинициализирован самый первый алгоритм (классификация, регрессия)
  - Зачем нужно вычислять градиент в данном методе?
  - Как происходит построение нового алгоритма?
  - Что приближает (чему эквивалентен) новый алгоритм
  - Чему эквивалентен алгоритм градиентного бустинга?
  - Основная причина переобучения ГБ?
  - Как бороться с переобучением в ГБ?
  - Как можно выбирать шаг в градиентном бустинге
  - Основные гиперпараметры градиентного бустинга
  - Какой метод получим если применим бутстреп при построении базовых алгоритмов?
  - Зачем применять бутстреп и шаг градиентного спуска в градиентном бустинге?
- На какую ошибку настраивается сруктура дерева в градиентном бустинге?
Week_5
- Что такое однослойная нейронная сеть? (объяснение + нарисовать)
- Какие требования предъявляются к функции активации?
- За что отвечает вес w0 (bias) в НС?
- Основные функции активации(сигмоидная, гипербалический тангенс, softsign, Relu)
- Почему необходимы многослойные НС?
- Основной метод обучения НС, его +/-
- Задача оптимизации НС и основные параметры сети
- Какими методами может быть осуществлена оптимизация НС, их +/-
- Какой метод регуляризации в НС можеть быть использован?
- Как определить какие нейроны можно выключить при обучении?
- Зачем нужно строить кривые обучения для НС?
- Обязателно ли функция активации должна быть дифференцируемой?
- Зачем использовать softmax?
Week_6
- В чем заключается суть байесовкской классификации?
- Пример наивной байесовской классификации на примере спам фильтра
- Правильный алгоритм наивного байесовского классификатора и КАКУЮ вероятность мы оцениваем?
- Как обучается наивный баес и сложности которые возникаюи/могут возникнуть?
- Какими способами может быть оценена P(x|y)?
- Что такое метрические алгоритмы?
- Интуиция метода KNN, взешенный KNN
- Можно ли при помощи KNN решать задачу регрессии, как решаем?
- Основные параметры KNN как их подбирать?
- Банальное определение метрики?
- Примеры метрик (три хватит) как определить лучшую?
- Проблема проклятия размерности
- Что представляет из себя алгоритм SVM (2 основных элемента метода)
- Что такое разделяющие полосы, и как их определить?
- Что такое ширина разделяющей полосы? Как она задется?
- Интуиция SVM
- Что максимизируем SVM (линейноразделимая и неразделимая выборки)
- SVM это линейная модель?
- Kernel Trick, зачем использовать?

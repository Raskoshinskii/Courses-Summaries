Week_1
- Основная задача кластеризации
- Примеры базовых метрик кластеризации (три)
- Почему столько много разных алгоритмов кластеризации?
- Как алгоритмы кластеризации могут отличаться друг от друга и почему?
- Существует ли универсальный метод кластеризации?
- Алгоритмы кластеризации:
  - KMeans (о методе, параметры, масштабируемость, метрика, KMeans++, что минимизирует)
  - Bisect Means (отличие от KMeans)
  - GaussinaMixture (о методе, параметры, масштабируемость, метрика)
  - Hierarchical Clustering (о методе, виды, масштабируемость, дендограмма, особенность метрик)
  - DBSCAN (о методе, параметры, масштабируемость, основные виды точек, определение гиперпараметров)
  - Графовая кластеризация (связность, минимальное остовное дерево и алгоритм Крускала)
- Метрики расстояния между кластерами (linkage)
- Мягкая и жесткая кластеризация, в чем отличие?
- 3 алгоритма которые дают обычно хорошую класетеризацию
- Коэффициент Силуэт
- Как определить есть ли кластерная структура. Идея статистики хопкинса?
- Зачем делать отбор признаков в кластеризации?
- Метрки, использующие разметку в кластеризации(их три + формулы)
* Davies Bouldin Index and Dunn Index
Week_2
- Зачем делать отбор признаков и на что это влияет?
- Могут ли признаки, сгенерированные случайно, коррелировать с таргетом и показывать большую Feature mportance ?
- Методы отбора признаков (основные методы)
  - Одномерный отбор (корреляция - проблемы метода, взаимная информация)
  - Жадные методы отбора признаков (полный перебор, жадное добаление, ADD-DEL) + В чем ADD-DEL лучше жадного добавления?
  - Отбор на основе моделей
    - В чем проблема неотмасштабированных признаков?
    - Как можно отбирать признаки, используя решающее дерево, композицию деревьев?
- Основная идея понижения размерности
- Методы понижения размерности:
  - Метод случайных проекций (основная идея метода, где обычно применяется)
  - Метод главных компонент (3 способа постановки задачи)
    - Как найти матрицу весов W в PCA?
    - PCA это линейный метод?
- Задача матричного разложения
- Что такое SVD разложение (проблемы метода)
- Примеры использования SVD в рекомендациях
- Оптимизация нормы фробениуса, используя SGD (плюсы/минусы)
- Оптимизация нормы фробениуса, используя метод ALS
- Как можно спрогнозировать неизвестные значения в матрице на примере рекомендации фильмов
- Implicit и Explicit feedback (проблема Implicit методов)
- Как адаптировать матричное разложения для Implicit случая?
- Вероятностный взгляд на матричное разложение
- Неотрицательные матричные расложения, в чем их достоинство?
- Что такое факторизация матриц?
- Основная особенность неотрицательных матричных разложений (NMF)
- Проблемы NMF
- Методы оптимизации NMF:
  - Мультипликативные обновления (суть, +/-)
  - Метод попеременных наменьших квадратов (ALS) (суть, +/-)
  - Метод попеременных неотрицательных наменьших квадратов (ANLS) (суть, +/-)
  - Метод иерархических попеременных наименьших квадратов (HALS) (суть, +/-)
- Основное ограничение на ФП для NMF
- Важна ли начальная инициализация для NMF
- Методы формирования начальных приближений
- Основное предпложение при работе с пропусками?
- Методы для борьбы с пропусками
Week_3
- Основная задача обнаружения аномалий?
- К какому классу задач относится задача обнаружения аномалий?
- 2 основных метода обнаружения аномалий
- Что такое аномалия с точки зрения вероятностного подхода?
- Методы восстановления распределений (три основных)
  - Что такое смесь распределений?
  - Основная проблема метода непараметрического восстановления плотности?
  - Какие параметры оцениваются на E и M шагах?
- Cуть одноклассового SVM?
- Зачем делать визуализацию признаков высокой размерности?
- Если классы хорошо разделимы в простарвнсе низкой размерности, то будут ли они хорошо разделимы в пространстве высокой размерности?
- Метод MDS (оптимизируемый функционал, проблема метода)
- Метод SNE и t-SNE
- Какой функцинал минимизируется в методе t-SNE?
Week_4
- Что такое тематическая модель?
- Задачи тематического моделирования?
- Процедура подготовки текста
- Что описывает вероятностная тематическая модель и какие допущения использует?
- Что такого особенного в распределении Дирихле, используемое в матрице Фи?
- Из какого распределения порождаются столбцы матрицы Фи и Тета?
- Метод LDA (Латентное размещение Дирихле) и какие распределения позволяет генерировать распределение Дирихле?
- Что позволяет измерять дивергенция Кульбака-Лейбнера?
- Перплексия, Перплексия Тестовой Коллекци(Hold-out Perplexity), Когерентность
